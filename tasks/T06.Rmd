---
title: "Task 6"
author: "GEOG-490R"
date: "Spring 2024"
output: 
  html_document:
    code_folding: hide
---

```{r echo=FALSE, message=FALSE}
library(dplyr);library(ggplot2)
```

### Pivoting, merging, and visualizing data

This week you will continue to explore manipulating data with `dplyr` and creating more complex visualizations with `ggplot`, both part of the tidyverse.

\

#### 1. Pivot and sort

Noah demonstrated how pivoting works in R. Many dataframes must be pivoted before you can visualize the information into `ggplot`. Review Noah's handout in the Canvas module.

Two base functions we've briefly discussed are `order` and `sort`. These are helpful methods to rearrange or sort data. Order returns the location of variables in their sequential order, and works for character or numeric data:
```{r, class.source = 'fold-show', eval=FALSE}
# reorder the values alphabetically
capletters <- c("B","Z","F","D","A","G","C")
order(capletters) # 5 1 7 4 3 6 2
# rearrange data with indexing
capletters[order(capletters)] # "A" "B" "C" "D" "F" "G" "Z"
```


Sort is a similar function to automatically reorder information. Note, these functions also work with numeric data.
```{r, class.source = 'fold-show', eval=FALSE}
# sort data
sort(capletters) # "A" "B" "C" "D" "F" "G" "Z"
# numeric example
num <- sample(12)
num # 2 8 10 11 5 7 12 6 1 9 3 4 
sort(num) # 1 2 3 4 5 6 7 8 9 10 11 12
```


`dplyr` has its own method of arranging data, though this is designed for working within one column in a dataframe:
```{r, class.source = 'fold-show', eval=FALSE}
as_tibble(capletters) %>% arrange(value) # value <chr> "A" "B" "C" "D" "F" "G" "Z"
```


\

#### 2. Join and match

Andrew demonstrated great implementations of merging dataframes with `full_join()` and `cbind()`, these are both excellent methods for joining datesets. Review Andrew's handout in the Canvas module. 

The match function returns the location of the match of x, which can be numeric or character:
```{r, class.source = 'fold-show', eval=FALSE}
match(5, 1:9) # 5
match(5, c(1,2,3,6,7,8,9,5)) # 8
match("B", c("A","B","C")) # 2
```

You can also use the `%in%` (wrapper for match) to return a logical expression to check if a value exists at all in the vector:
```{r, class.source = 'fold-show', eval=FALSE}
capletters <-  c("B","Z","F","D","A","G","C")
"A" %in% capletters # TRUE
"J" %in% capletters # FALSE
5 %in% 1:9 # TRUE
```


Let's use a more useful example, focusing on two small datasets for 10 US states.

The first is a subset of the state_flags dataframe Andrew used:

```{r}
stateflags <- data.frame(
  state = c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia"),
  flag = c("Red, White", "Blue, Gold", "Blue, Gold", "Red, White", "Blue, Gold", "Red, White", "Blue, White", "Blue, Yellow", "Red, White", "Red, White")
  )
stateflags
```

Now, let's add another dataset with information we wanted to join:

```{r}
stateinfo <- data.frame(
  state = c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia"),
  areakm2 = c(135767,1723337,295234,137732,423967,269601,14357,6446,170312,153910),
  pop2020 = c(5024279,733391,7151502,3011524,39538223,5773714,3605944,989948,21538187,10711908)
  )
stateinfo <- stateinfo[sample(nrow(stateinfo)),]
stateinfo
```

First, let's try to use `cbind` to combine these datasets. This function simply sticks these dataframes together.

```{r}
# cbind
cbind(stateflags, stateinfo) %>% head()
```

**That is incorrect!** As you can see, this is a very poor join between these dataframes. Instead we can use match with like-variables between datasets to make sure that the join is correct

```{r}
# cbind with match
match_id <- match(stateflags$state, stateinfo$state)
cbind(stateflags, stateinfo[match_id,]) %>%
  head()
```

Although it is useful to check, we would want to omit the second column instance of state names.

Alternatively, we could use dplyr funtions like `full_join` to do the work:

```{r}
full_join(stateflags, stateinfo, by="state") %>%
  head()
```

Note that there are several creative ways to match and join dataframes. For example, let's use the `order` function from earlier on each dataset with `cbind`. Many ways to skin a cat!

```{r}
stateinfo_order <- stateinfo[order(stateinfo$state),]
cbind(stateflags, stateinfo_order) %>% head()
```

Data analysis often requires combining several datasets prior to analyzing. For more information seek examples in our online texts or other websites.

\

#### Your Task

Your task this week will include pivoting, combining, and visualizing data. 

Read in the "UTSNTL_ALL_2020_2022_Daily_Wide.csv" dataset. This file contains meteorological and snow data from snow telemetry (snotel) weather stations in the mountains of Utah. Data from three winter seasons in 2020-21, 2021-22, and 2022-23 were added to this dataset. Several different variables are included for each station.

Note that the water year or winter season begins on Oct 1st and goes until Sep 31st of the following year.

\

#### 1. Advanced visualization with ggplot

**No transformation (pivoting)** is required to complete this section.

Recreate the following plot using `ggplot`:

```{r echo=FALSE}
snowide <- "../tmp/tmp_data/UTSNTL_ALL_2020_2022_Daily_Wide.csv"
dfw <- read.csv(snowide)
# plot swe and temperature of one site
scal = 3
dfw %>% mutate(Date=as.Date(Date,format="%m/%d/%y")) %>%
  mutate(t_color = if_else(Agua.Canyon..907..Air.Temperature.Average..degF. > 32, "No", "Yes")) %>% 
  ggplot(aes(x=Date)) +
  geom_bar(aes(y = Agua.Canyon..907..Snow.Water.Equivalent..in..Start.of.Day.Values),
           col='lightblue', stat='identity') +
  geom_line(aes(y = Agua.Canyon..907..Air.Temperature.Average..degF. / scal, color=t_color, group=1 ), size=0.5) +
  scale_y_continuous(name = "SWE (inches)",
    sec.axis = sec_axis( trans=~.*scal, name="Temperature (degF)")) +
  scale_color_manual(values=c("firebrick","deepskyblue3"),name="Freezing") +
  theme_bw() +
  theme(
    axis.title.y = element_text(color = "lightblue4"),
    axis.text.y = element_text(color = "lightblue4"),
    axis.title.y.right = element_text(color = "firebrick"),
    axis.text.y.right = element_text(color = "firebrick")
  ) +
  labs(title="Agua Canyon Snotel 2020-2023")

```

1. (5 points) Provide a script to recreate the plot above. This shows the SWE for all three seasons alongside average air temperature for the first listed snotel station (Agua Canyon).

***Tips: try on your own, then click "Code" to reveal a few hints:***

```{r, eval=FALSE}
# Note: multiple geom_line() or other plotting variables can be called within the same plot for multiple variables
# You will need to create a new variable that states whether the temperature value is below the freezing point

# To include y axes on both the right and left for each variable, use: 
scale_y_continuous(name = "first axis title", sec.axis = sec_axis( trans=~.*scale_factor, name="second axis title")) 
# note: the scale_factor variable is used to allow you to plot to variables of different ranges side-by-side
#   the scale_factor should be applied to both the variable (i.e. ggplot(aes(x=..., y=variable/scale_factor)) ) and axis (code above) to scale the values to align with the other variable
#   you will need to play around and adjust the scale factor to fit both variables

# within the `theme()` function, you can include arguments like:" 
axis.title.y.right = element_text(color = "firebrick") # make firght axis title red
```

\

#### 2. Pivoting and arranging

**You must pivot** the data to answer and complete the following.   

2. How many stations are there in total? How many variables are included for each? Provide code for your response.

3. (5 points) Show the top 5 snotel sites with the deepest snow depth for each winter season. Include the max snow depth value (inches) and the Date of max snow depth for each season. Try to generate a single final table table showing this with one continuous piped dplyr statement.

***Tips: try on your own, then click "Code" to reveal hints if needed***

***Variable names and regex tips:***

```{r, eval=FALSE}
# Note: you can accomplish the tasks above without the use of regex! However, parsing character strings a great task for regex.

## Regex help - from one perspective:
#   regex can be useful to extract more manageable variable names, for example, try the following on a subset of the column names of the initial dataset:
names(data_frame_snotel)[2:11] # shows first 10 column names after Date
#   it's difficult to work with . characters, so change them to "_" or something else:
gsub(pattern = "\\.", replacement = "_", x = names(data_frame_snotel)[2:11]) # show only first 10
#   can replace names with: names(data_frame_snotel) <- ..code above..
#   you can also extract part of a string rather than replace with the "\\1" replacement option:
gsub(pattern = "^(.*)__[0-9]+.*$", replacement = "\\1", x = data_frame_snotel) # site names in wide (original) format
#   note: the pattern above groups (.*) what you want to keep (i.e. the part before the ..numbers)
#   you can also extract more than one variable: 
gsub("^(.*)__[0-9]+__(.*)__.*$", replacement = "\\2", x = data_frame_snotel) # keep second (\\2) grouped argument which is the variable

## Combine this with pivot_longer()
#   the pivot_ functions have an option to match multiple variables within a column name
#   you can use these arguments within the pivot_longer function:
#   names_to = ... (list name(s) to extract to new column(s))
#   names_pattern = ... (use regex pattern)
#   to read more about this, fo to the ?pivot_wider help doc and look at the example for multiple names_from option
#   NOTE: you do not need to follow this solution, there are other ways as well


#  note: the last lines above assume all "." are now "_" for this dataset
```

***Pivoting tips:***

```{r, eval=FALSE}
## Selecting columns:
#   pivot all data by excluding only the Date column
#   a useful tip is that you can call on columns by using either the starts_with() or contains() functions in the argument
#   note: this can be used within the pivot_longer(), select(), or other functions

## Selecting/filtering a specific variable
#   remember that select() is used to filter column names and filter() is used to filter by rows based on a boolean expression
#   you may use either before, during or after pivoting to select one variable
#   remember that the contains() function can be useful to extract specific strings:
data_frame_snotel %>% select(contains("Air.Temperature.Maximum")) %>%
  head()

## Pivoting multiple variables
#   you could break down these steps and combine subdatasets
#   but even better, you could extract all variables in the column names of this dataset
#   see the example in the previous tip box about pivoting multiple variables
#   or use ?pivot_longer


```

***Winter seasons and snow depth max tips:***

```{r, eval=FALSE}
# after pivoting...

## Determine seasons
#   be sure to convert characters to date format
#   then you can use the following code to create a new seasonal variable in the dataframe: 
cut(Date, breaks =  c(as.Date(c("2020-10-01", "2021-10-01", "2022-10-01")), Inf), labels = paste0("season_", c(1, 2, 3)))
#   ^this code basically creates a new vector that is the same length as your Date variable and groups the dates into seasons (1, 2, or 3) based on the Oct 1st breaks given

## Summarize the data
#   you need to use group_by() to establish how to summarize() your data
#   arrange() or filter() could also be used, but I did not
#   which.max() along with indexing can be useful to extract the date with the deepest snow
#   show the top 5 stations with the deepest snow depth for each season
#   to do so, you will need to use group_by() again (after summarize()) and then subset the data to only show the top 5 
#   subsetting can be achieved with filter(), arrange(), or the slice_max() function to combine a several steps
```



\

Perform a join with the data above and  the "UTSNTL_ELEV.csv" file. Show code for your join and complete the following:

4. (4) Create a plot that shows the median SWE for stations along four different elevation zones in Utah. Create zones based on the quantile distribution of the elevation range (i.e. group1 contains stations with elevations in 0-25% quantile or lower fourth, group2 from 25-50%, etc.). Use facet_wrap to show the SWE plots of different elevation zones side-by side and show the average SWE for each season (different colors) for each zone.


5. What is the mean and median day of peak SWE for each elevation zone during these three seasons?


# pivot_long - intro - filter variables and do one, for advanced do all
# determine number of stations
# seasonality
# generate graph for two 
# relationships between temp and swe
# peak swe

# 


\

#### Submitting

Upload your R Markdown output as an html file to Canvas

\

**This assignment is due in one week but may be turned for an additional week with a late penalty of -5%**

\
References:


\
